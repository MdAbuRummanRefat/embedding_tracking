{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from experiment import Experiment\n",
    "from params import Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yliu60\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yliu60\\Documents\\GitHub\\embedding_tracking\\deeplabv3\\model.py:87: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yliu60\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\yliu60\\Documents\\GitHub\\embedding_tracking\\loss_functions.py:141: The name tf.diag is deprecated. Please use tf.linalg.tensor_diag instead.\n",
      "\n",
      "Loading weights from model/6_shapes\\1.h5\n",
      "Evaluating model\n",
      "Sequence 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\yliu60\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Sequence 2/10\n",
      "Sequence 3/10\n",
      "Sequence 4/10\n",
      "Sequence 5/10\n",
      "Sequence 6/10\n",
      "Sequence 7/10\n",
      "Sequence 8/10\n",
      "Sequence 9/10\n",
      "Sequence 10/10\n",
      "Matching hypothesis with ground truth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yliu60\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\motmetrics\\mot.py:243: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n",
      "  idx = pd.MultiIndex(levels=[[],[]], labels=[[],[]], names=['FrameId','Event'])\n"
     ]
    }
   ],
   "source": [
    "params = Params()\n",
    "\n",
    "params.EMBEDDING_DIM            = 24\n",
    "params.BATCH_SIZE               = 1\n",
    "params.NUM_SHAPE                = 6\n",
    "params.NUM_CLASSES              = 4 # (3 shapes + 1 background)\n",
    "params.NUM_FILTER               = [256, 128]\n",
    "params.ETH_MEAN_SHIFT_THRESHOLD = 1.5\n",
    "params.DELTA_VAR                = 0.5\n",
    "params.DELTA_D                  = 1.5\n",
    "params.IMG_SIZE                 = 256\n",
    "params.OUTPUT_SIZE              = 64\n",
    "params.SEQUENCE_LEN             = 100\n",
    "params.TRAIN_NUM_SEQ            = 500\n",
    "params.VAL_NUM_SEQ              = 5\n",
    "params.TEST_NUM_SEQ             = 10\n",
    "params.RANDOM_SIZE              = True\n",
    "params.OPTICAL_FLOW_WEIGHT      = 0\n",
    "params.BACKBONE                 = 'xception'\n",
    "params.GITHUB_DIR               = 'C:/Users/yliu60/Documents/GitHub'\n",
    "params.LEARNING_RATE            = 1e-4\n",
    "params.EPOCHS                   = 10\n",
    "params.EPOCHS_PER_SAVE          = 1\n",
    "params.STEPS_PER_VISUAL         = 1000\n",
    "params.FEATURE_STRING           = f'{params.NUM_SHAPE}_shapes'\n",
    "params.MODEL_SAVE_DIR           = f'model/{params.NUM_SHAPE}_shapes'\n",
    "params.TRAIN_SET_PATH           = f'dataset/{params.NUM_SHAPE}_shapes/train'\n",
    "params.VAL_SET_PATH             = f'dataset/{params.NUM_SHAPE}_shapes/val'\n",
    "params.TEST_SET_PATH            = f'dataset/{params.NUM_SHAPE}_shapes/test'\n",
    "params.IOU_THRESHOLD            = 0.5\n",
    "params.MASK_AREA_THRESHOLD      = 20\n",
    "\n",
    "experiment = Experiment(params)\n",
    "experiment.init_model()\n",
    "experiment.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.model.save_weights('model/6_shapes/1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval\n",
    "\n",
    "sequence = experiment.val_data_loader.get_next_sequence()\n",
    "evaluator = eval.MaskTrackEvaluator(iou_threshold=experiment.params.IOU_THRESHOLD)\n",
    "gt_sequence = evaluator.gen_target_sequence(sequence)\n",
    "tracks = experiment.inference_model.track_on_sequence(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = SequenceDataGenerator(\n",
    "    num_shape    = params.NUM_SHAPE, \n",
    "    image_size   = params.IMG_SIZE,\n",
    "    sequence_len = params.SEQUENCE_LEN)\n",
    "sequence = dg.get_sequence()\n",
    "image_info = sequence[0]\n",
    "prev_image_info = sequence[1]\n",
    "x, y = prep_double_frame(image_info, prev_image_info, params)\n",
    "outputs = np.random.rand(1, 64, 64, 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "y_true = tf.placeholder(dtype = tf.float32, shape = (1, 32, 32, 6))\n",
    "y_pred = tf.placeholder(dtype = tf.float32, shape = (1, 32, 32, 34))\n",
    "\n",
    "delta_var     = params.DELTA_VAR\n",
    "delta_d       = params.DELTA_D\n",
    "class_num     = params.NUM_CLASSES\n",
    "embedding_dim = params.EMBEDDING_DIM\n",
    "\n",
    "# unpack ground truth contents\n",
    "class_mask_gt      = y_true[:, :, :, 0]\n",
    "prev_class_mask_gt = y_true[:, :, :, 1]\n",
    "identity_mask      = y_true[:, :, :, 2]\n",
    "prev_identity_mask = y_true[:, :, :, 3]\n",
    "optical_flow_gt    = y_true[:, :, :, 4:5]\n",
    "\n",
    "# y_pred\n",
    "class_mask_pred      = y_pred[:, :, :, :class_num]\n",
    "prev_class_mask_pred = y_pred[:, :, :, class_num:(class_num * 2)]\n",
    "instance_emb         = y_pred[:, :, :, (class_num * 2):(class_num * 2 + embedding_dim)]\n",
    "prev_instance_emb    = y_pred[:, :, :, (class_num * 2 + embedding_dim):(class_num * 2 + embedding_dim * 2)]\n",
    "optical_flow_pred    = y_pred[:, :, :, (class_num * 2 + embedding_dim * 2):]\n",
    "\n",
    "# flatten and combine\n",
    "# --identity mask gt\n",
    "identity_mask_flat            = K.flatten(identity_mask)\n",
    "prev_identity_mask_flat       = K.flatten(prev_identity_mask)\n",
    "combined_identity_mask_flat   = tf.concat((identity_mask_flat, prev_identity_mask_flat), axis=0)\n",
    "# --instance embedding pred\n",
    "instance_emb_flat             = tf.reshape(instance_emb, shape=(-1, embedding_dim))\n",
    "prev_instance_emb_flat        = tf.reshape(prev_instance_emb, shape=(-1, embedding_dim))\n",
    "combined_instance_emb_flat    = tf.concat((instance_emb_flat, prev_instance_emb_flat), axis=0)\n",
    "# --class mask gt\n",
    "class_mask_gt_flat            = K.flatten(class_mask_gt)\n",
    "prev_class_mask_gt_flat       = K.flatten(prev_class_mask_gt)\n",
    "combined_class_mask_gt_flat   = tf.concat((class_mask_gt_flat, prev_class_mask_gt_flat), axis=0)\n",
    "# --class mask pred\n",
    "class_mask_pred_flat          = tf.reshape(class_mask_pred, shape=(-1, class_num))\n",
    "prev_class_mask_pred_flat     = tf.reshape(prev_class_mask_pred, shape=(-1, class_num))\n",
    "combined_class_mask_pred_flat = tf.concat((class_mask_pred_flat, prev_class_mask_pred_flat), axis=0)\n",
    "\n",
    "# get number of pixels and clusters (without background)\n",
    "num_cluster = tf.reduce_max(combined_identity_mask_flat)\n",
    "num_cluster = tf.cast(num_cluster, tf.int32)\n",
    "\n",
    "# cast masks into tf.int32 for one-hot encoding\n",
    "combined_identity_mask_flat = tf.cast(combined_identity_mask_flat, tf.int32)\n",
    "combined_class_mask_gt_flat = tf.cast(combined_class_mask_gt_flat, tf.int32)\n",
    "\n",
    "# one-hot encoding\n",
    "combined_identity_mask_flat -= 1\n",
    "combined_identity_mask_flat_one_hot = tf.one_hot(combined_identity_mask_flat, num_cluster)\n",
    "conbined_class_mask_gt_flat_one_hot = tf.one_hot(combined_class_mask_gt_flat, class_num)\n",
    "\n",
    "# ignore background pixels\n",
    "non_background_idx                  = tf.greater(combined_identity_mask_flat, -1)\n",
    "combined_instance_emb_flat          = tf.boolean_mask(combined_instance_emb_flat, non_background_idx)\n",
    "combined_identity_mask_flat         = tf.boolean_mask(combined_identity_mask_flat, non_background_idx)\n",
    "combined_identity_mask_flat_one_hot = tf.boolean_mask(combined_identity_mask_flat_one_hot, non_background_idx)\n",
    "combined_class_mask_gt_flat         = tf.boolean_mask(combined_class_mask_gt_flat, non_background_idx)\n",
    "\n",
    "# center count\n",
    "combined_identity_mask_flat_one_hot = tf.cast(combined_identity_mask_flat_one_hot, tf.float32)\n",
    "center_count = tf.reduce_sum(combined_identity_mask_flat_one_hot, axis=0)\n",
    "# add a small number to avoid division by zero\n",
    "\n",
    "# variance term\n",
    "embedding_sum_by_instance = tf.matmul(\n",
    "    tf.transpose(combined_instance_emb_flat), combined_identity_mask_flat_one_hot)\n",
    "centers = tf.math.divide_no_nan(embedding_sum_by_instance, center_count)\n",
    "gathered_center = tf.gather(centers, combined_identity_mask_flat, axis=1)\n",
    "gathered_center_count = tf.gather(center_count, combined_identity_mask_flat)\n",
    "combined_emb_t = tf.transpose(combined_instance_emb_flat)\n",
    "var_dist = tf.norm(combined_emb_t - gathered_center, ord=1, axis=0) - delta_var\n",
    "# changed from soft hinge loss to hard cutoff\n",
    "var_dist_pos = tf.square(tf.maximum(var_dist, 0))\n",
    "var_dist_by_instance = tf.math.divide_no_nan(var_dist_pos, gathered_center_count)\n",
    "num_cluster = tf.cast(num_cluster, tf.float32)\n",
    "variance_term = tf.math.divide_no_nan(\n",
    "    tf.reduce_sum(var_dist_by_instance),\n",
    "    tf.cast(num_cluster, tf.float32))\n",
    "\n",
    "# get instance to class mapping\n",
    "class_mask_gt = tf.expand_dims(class_mask_gt, axis=-1)\n",
    "# multiply classification with one hot flat identity mask\n",
    "combined_class_mask_gt_flat = tf.cast(combined_class_mask_gt_flat, tf.float32)\n",
    "combined_class_mask_gt_flat = tf.expand_dims(combined_class_mask_gt_flat, 1)\n",
    "filtered_class = tf.multiply(combined_identity_mask_flat_one_hot, combined_class_mask_gt_flat)\n",
    "# shrink to a 1 by num_of_cluster vector to map instance to class;\n",
    "# by reduce_max, any class other than 0 (background) stands out\n",
    "instance_to_class = tf.reduce_max(filtered_class, axis = [0])\n",
    "\n",
    "def distance_true_fn(num_cluster_by_class, centers_by_class):\n",
    "    centers_row_buffer = tf.ones((embedding_dim, num_cluster_by_class, num_cluster_by_class))\n",
    "    centers_by_class = tf.expand_dims(centers_by_class, axis=2)\n",
    "    centers_row = tf.multiply(centers_row_buffer, centers_by_class)\n",
    "    centers_col = tf.transpose(centers_row, perm=[0, 2, 1])\n",
    "    dist_matrix = centers_row - centers_col\n",
    "    idx2 = tf.ones((num_cluster_by_class, num_cluster_by_class))\n",
    "    diag = tf.ones((1, num_cluster_by_class))\n",
    "    diag = tf.reshape(diag, [-1])\n",
    "    idx2 = idx2 - tf.diag(diag)\n",
    "    idx2 = tf.cast(idx2, tf.bool)\n",
    "    idx2 = K.flatten(idx2)\n",
    "    dist_matrix = tf.reshape(dist_matrix, [embedding_dim, -1])\n",
    "    dist_matrix = tf.transpose(dist_matrix)\n",
    "    sampled_dist = tf.boolean_mask(dist_matrix, idx2)\n",
    "    distance_term = tf.square(tf.maximum(\n",
    "        2 * delta_d - tf.norm(sampled_dist, ord=1, axis=1), 0))\n",
    "    total_cluster_pair = num_cluster_by_class * (num_cluster_by_class - 1) + 1\n",
    "    total_cluster_pair = tf.cast(total_cluster_pair, tf.float32)\n",
    "    distance_term = tf.math.divide_no_nan(tf.reduce_sum(distance_term), total_cluster_pair)\n",
    "    return distance_term\n",
    "\n",
    "\n",
    "def distance_false_fn():\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "distance_term_total = 0.0\n",
    "# center distance term\n",
    "for i in range(class_num-1):\n",
    "    class_idx = tf.equal(instance_to_class, i+1)\n",
    "    centers_transpose = tf.transpose(centers)\n",
    "    centers_by_class_transpose = tf.boolean_mask(centers_transpose, class_idx)\n",
    "    centers_by_class = tf.transpose(centers_by_class_transpose)\n",
    "    num_cluster_by_class = tf.reduce_sum(tf.cast(class_idx, tf.float32))\n",
    "    num_cluster_by_class = tf.cast(num_cluster_by_class, tf.int32)\n",
    "    distance_term_subtotal = tf.cond(num_cluster_by_class > 0, \n",
    "                                    lambda: distance_true_fn(num_cluster_by_class, centers_by_class), \n",
    "                                    lambda: distance_false_fn())\n",
    "    distance_term_total += distance_term_subtotal\n",
    "\n",
    "# regularization term\n",
    "regularization_term = tf.reduce_mean(tf.norm(tf.squeeze(centers), ord=1, axis=0))\n",
    "\n",
    "# sum up terms\n",
    "instance_emb_sequence_loss = variance_term + distance_term_total + 0.01 * regularization_term\n",
    "semseg_loss = K.mean(K.categorical_crossentropy(\n",
    "    tf.cast(conbined_class_mask_gt_flat_one_hot, tf.float32), \n",
    "    tf.cast(combined_class_mask_pred_flat, tf.float32)))\n",
    "# masked mse for optical loss\n",
    "flow_mask = tf.greater(prev_class_mask_gt, 0)\n",
    "flow_mask = tf.cast(flow_mask, tf.float32)\n",
    "flow_mask = tf.expand_dims(flow_mask, axis = -1)\n",
    "masked_optical_flow_pred = tf.math.multiply(optical_flow_pred, flow_mask)\n",
    "optical_flow_loss = tf.reduce_mean(tf.square(masked_optical_flow_pred - optical_flow_gt))\n",
    "# loss = instance_emb_sequence_loss + semseg_loss + optical_flow_loss\n",
    "loss = optical_flow_loss\n",
    "loss = tf.reshape(loss, [-1])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    [masked_optical_flow_pred_, optical_flow_gt_] = sess.run(\n",
    "        [masked_optical_flow_pred, optical_flow_gt], \n",
    "        feed_dict = {'Placeholder:0': y, 'Placeholder_1:0': outputs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(flow_to_rgb(np.squeeze(optical_flow_gt_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(flow_to_rgb(np.squeeze(masked_optical_flow_pred_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class value:\n",
    "    def __init__(self, x):\n",
    "        self.val = x\n",
    "    \n",
    "    def increment(self):\n",
    "        self.val += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class temp:\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "        print(id(x))\n",
    "        print(id(self.x))\n",
    "        x.increment()\n",
    "        print(id(x))\n",
    "        print(id(self.x))\n",
    "        print(x.val)\n",
    "        print(self.x.val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = value(1)\n",
    "b = temp(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
