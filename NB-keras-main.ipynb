{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from experiment import Experiment\n",
    "from params import Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from model/6_shapes\\9.h5\n"
     ]
    }
   ],
   "source": [
    "params = Params()\n",
    "\n",
    "params.EMBEDDING_DIM            = 24\n",
    "params.BATCH_SIZE               = 1\n",
    "params.NUM_SHAPE                = 6\n",
    "params.NUM_CLASSES              = 4 # (3 shapes + 1 background)\n",
    "params.NUM_FILTER               = [256, 128]\n",
    "params.ETH_MEAN_SHIFT_THRESHOLD = 1.5\n",
    "params.DELTA_VAR                = 0.5\n",
    "params.DELTA_D                  = 1.5\n",
    "params.IMG_SIZE                 = 256\n",
    "params.OUTPUT_SIZE              = 64\n",
    "params.SEQUENCE_LEN             = 100\n",
    "params.TRAIN_NUM_SEQ            = 500\n",
    "params.VAL_NUM_SEQ              = 5\n",
    "params.TEST_NUM_SEQ             = 10\n",
    "params.RANDOM_SIZE              = True\n",
    "params.OPTICAL_FLOW_WEIGHT      = 0\n",
    "params.BACKBONE                 = 'xception'\n",
    "params.GITHUB_DIR               = 'C:/Users/yliu60/Documents/GitHub'\n",
    "params.LEARNING_RATE            = 1e-4\n",
    "params.EPOCHS                   = 10\n",
    "params.EPOCHS_PER_SAVE          = 1\n",
    "params.STEPS_PER_VISUAL         = 1000\n",
    "params.ROTATE_SHAPES            = False\n",
    "params.FEATURE_STRING           = f'{params.NUM_SHAPE}_shapes'\n",
    "params.MODEL_SAVE_DIR           = f'model/{params.FEATURE_STRING}'\n",
    "params.TRAIN_SET_PATH           = f'dataset/{params.FEATURE_STRING}/train'\n",
    "params.VAL_SET_PATH             = f'dataset/{params.FEATURE_STRING}/val'\n",
    "params.TEST_SET_PATH            = f'dataset/{params.FEATURE_STRING}/test'\n",
    "params.IOU_THRESHOLD            = 0.5\n",
    "params.MASK_AREA_THRESHOLD      = 20\n",
    "\n",
    "experiment = Experiment(params)\n",
    "# experiment.run()\n",
    "experiment.init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import utils\n",
    "import visual\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(10):\n",
    "    sequence = experiment.val_datagen.get_sequence()\n",
    "    frames = experiment.inference_model.track_on_sequence(sequence)\n",
    "    colors = np.random.rand(1000, 3)\n",
    "    utils.mkdir_if_missing(f'demo/seq_{j}')\n",
    "    for i in range(len(frames)):\n",
    "        frame = frames[i]\n",
    "        info = sequence[i]\n",
    "        image = info['image'].astype(np.float32)\n",
    "        board = np.zeros((256, 256 * 2, 3))\n",
    "        board[:, :256, :] = image\n",
    "        half_board = np.zeros((256, 256, 3))\n",
    "        for target in frame:\n",
    "            mask = utils.resize_img(target.mask, 256, 256)\n",
    "            half_board[mask == 1] = colors[target.id, :]\n",
    "        board[:, 256:, :] = half_board\n",
    "        board = board * 255\n",
    "        board = board.astype(np.uint8)\n",
    "        cv2.imwrite(f'demo/seq_{j}/seq_{j}_track_{i}.png', board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCAViz:\n",
    "    def __init__(self, verbose:bool=False):\n",
    "        self.verbose = verbose\n",
    "        self.PCs = None\n",
    "        self.e_mu = None\n",
    "        self.e_std = None\n",
    "    def recalculate(self, e_flat:np.array):\n",
    "        cm = np.cov( np.transpose(e_flat) )\n",
    "        evals, evects = np.linalg.eig( cm )\n",
    "        order = np.argsort(evals)[::-1]\n",
    "        evals = evals[order]\n",
    "        evects = evects[:, order]       \n",
    "        return evects\n",
    "    def feed(self, e_flat, mask_flat, out_dims='all', show:bool=False):\n",
    "        dim = e_flat.shape[0]\n",
    "        e_flat_original = np.zeros((dim, out_dims))\n",
    "        idx = mask_flat == 1\n",
    "        e_flat = e_flat[idx]\n",
    "        if self.PCs is None:\n",
    "            if self.verbose:\n",
    "                print('Reclaculating')\n",
    "            self.PCs = self.recalculate(e_flat)\n",
    "            self.e_mu = np.mean( e_flat,0 )\n",
    "            self.e_std = np.std( e_flat,0 )\n",
    "        if out_dims is 'all':\n",
    "            out_dims = self.PCs.shape[0]\n",
    "        scores_flat = np.matmul( (e_flat-self.e_mu)/self.e_std , self.PCs)\n",
    "        scores_flat = scores_flat[:, :out_dims]\n",
    "        mask_flat = np.expand_dims(mask_flat, axis=-1)\n",
    "        scores_flat = utils.normalize(scores_flat)\n",
    "        e_flat_original[idx] = scores_flat\n",
    "        return e_flat_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num     = params.NUM_CLASSES\n",
    "embedding_dim = params.EMBEDDING_DIM\n",
    "image_size    = params.IMG_SIZE\n",
    "OS            = params.OUTPUT_SIZE\n",
    "video_name    = 'video/continuous_emb.avi'\n",
    "fps = 5\n",
    "\n",
    "boards = []\n",
    "sequence = experiment.val_datagen.get_sequence()\n",
    "\n",
    "for i in range(len(sequence) - 1):\n",
    "    prev_image = sequence[i]['image']\n",
    "    image = sequence[i+1]['image']\n",
    "    board = np.zeros((image_size * 2, image_size * 2, 3))\n",
    "    x, _ = utils.prep_double_frame(sequence[i], sequence[i+1])\n",
    "    outputs = experiment.model.predict(x)\n",
    "    outputs = np.squeeze(outputs)\n",
    "    embedding_pred = outputs[:, :, (class_num*2):(class_num*2 + embedding_dim)]\n",
    "    prev_embedding_pred = outputs[:, :, (class_num*2 + embedding_dim):((class_num*2 + embedding_dim*2))]\n",
    "    combined_embedding_pred = np.zeros((OS, OS*2, embedding_dim))\n",
    "    combined_embedding_pred[:, :OS, :] = prev_embedding_pred\n",
    "    combined_embedding_pred[:, OS:, :] = embedding_pred\n",
    "    board[:image_size, :image_size, :] = prev_image\n",
    "    board[:image_size, image_size:, :] = image\n",
    "    height, width, _ = combined_embedding_pred.shape\n",
    "    embedding_pred_flat = np.reshape(combined_embedding_pred, (-1, embedding_dim))\n",
    "    pcaviz = PCAViz()\n",
    "    scores_3 = pcaviz.feed(embedding_pred_flat, out_dims = 3)\n",
    "    pc = np.reshape(scores_3, (height, width, 3))\n",
    "    pc = utils.normalize(pc)\n",
    "    pc = utils.resize_img(pc, image_size, image_size*2)\n",
    "    board[image_size:, :, :] = pc\n",
    "    board = visual.float_to_uint8(board)\n",
    "    boards.append(board)\n",
    "visual.imgs_to_video(boards, video_name, fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num     = params.NUM_CLASSES\n",
    "embedding_dim = params.EMBEDDING_DIM\n",
    "image_size    = params.IMG_SIZE\n",
    "OS            = params.OUTPUT_SIZE\n",
    "nD            = params.EMBEDDING_DIM\n",
    "boards = []\n",
    "video_name = 'video/test.avi'\n",
    "pcaviz = PCAViz()\n",
    "for i in range(len(sequence) - 1):\n",
    "    prev_image_info = sequence[i]\n",
    "    image_info = sequence[i+1]\n",
    "    x, _ = utils.prep_double_frame(prev_image_info, image_info)\n",
    "    combined_embedding_pred, combined_class_mask_pred_int, cluster_all_class = experiment.inference_model.segment(x)\n",
    "    width, height, _ = combined_embedding_pred.shape\n",
    "    embedding_pred_flat = np.reshape(combined_embedding_pred, (-1, nD))\n",
    "    mask_flat = np.reshape(combined_class_mask_pred_int, (-1,))\n",
    "    masked_emb_flat = pcaviz.feed(embedding_pred_flat, mask_flat > 0, 3)\n",
    "    masked_emb = np.reshape(masked_emb_flat, (width, height, 3))\n",
    "    masked_emb = utils.resize_img(masked_emb, image_size, image_size * 4)\n",
    "    board = visual.float_to_uint8(masked_emb)\n",
    "    boards.append(board)\n",
    "visual.imgs_to_video(boards, video_name, fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval\n",
    "\n",
    "sequence = experiment.val_data_loader.get_next_sequence()\n",
    "evaluator = eval.MaskTrackEvaluator(iou_threshold=experiment.params.IOU_THRESHOLD)\n",
    "gt_sequence = evaluator.gen_target_sequence(sequence)\n",
    "tracks = experiment.inference_model.track_on_sequence(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = SequenceDataGenerator(\n",
    "    num_shape    = params.NUM_SHAPE, \n",
    "    image_size   = params.IMG_SIZE,\n",
    "    sequence_len = params.SEQUENCE_LEN)\n",
    "sequence = dg.get_sequence()\n",
    "image_info = sequence[0]\n",
    "prev_image_info = sequence[1]\n",
    "x, y = prep_double_frame(image_info, prev_image_info, params)\n",
    "outputs = np.random.rand(1, 64, 64, 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "y_true = tf.placeholder(dtype = tf.float32, shape = (1, 32, 32, 6))\n",
    "y_pred = tf.placeholder(dtype = tf.float32, shape = (1, 32, 32, 34))\n",
    "\n",
    "delta_var     = params.DELTA_VAR\n",
    "delta_d       = params.DELTA_D\n",
    "class_num     = params.NUM_CLASSES\n",
    "embedding_dim = params.EMBEDDING_DIM\n",
    "\n",
    "# unpack ground truth contents\n",
    "class_mask_gt      = y_true[:, :, :, 0]\n",
    "prev_class_mask_gt = y_true[:, :, :, 1]\n",
    "identity_mask      = y_true[:, :, :, 2]\n",
    "prev_identity_mask = y_true[:, :, :, 3]\n",
    "optical_flow_gt    = y_true[:, :, :, 4:5]\n",
    "\n",
    "# y_pred\n",
    "class_mask_pred      = y_pred[:, :, :, :class_num]\n",
    "prev_class_mask_pred = y_pred[:, :, :, class_num:(class_num * 2)]\n",
    "instance_emb         = y_pred[:, :, :, (class_num * 2):(class_num * 2 + embedding_dim)]\n",
    "prev_instance_emb    = y_pred[:, :, :, (class_num * 2 + embedding_dim):(class_num * 2 + embedding_dim * 2)]\n",
    "optical_flow_pred    = y_pred[:, :, :, (class_num * 2 + embedding_dim * 2):]\n",
    "\n",
    "# flatten and combine\n",
    "# --identity mask gt\n",
    "identity_mask_flat            = K.flatten(identity_mask)\n",
    "prev_identity_mask_flat       = K.flatten(prev_identity_mask)\n",
    "combined_identity_mask_flat   = tf.concat((identity_mask_flat, prev_identity_mask_flat), axis=0)\n",
    "# --instance embedding pred\n",
    "instance_emb_flat             = tf.reshape(instance_emb, shape=(-1, embedding_dim))\n",
    "prev_instance_emb_flat        = tf.reshape(prev_instance_emb, shape=(-1, embedding_dim))\n",
    "combined_instance_emb_flat    = tf.concat((instance_emb_flat, prev_instance_emb_flat), axis=0)\n",
    "# --class mask gt\n",
    "class_mask_gt_flat            = K.flatten(class_mask_gt)\n",
    "prev_class_mask_gt_flat       = K.flatten(prev_class_mask_gt)\n",
    "combined_class_mask_gt_flat   = tf.concat((class_mask_gt_flat, prev_class_mask_gt_flat), axis=0)\n",
    "# --class mask pred\n",
    "class_mask_pred_flat          = tf.reshape(class_mask_pred, shape=(-1, class_num))\n",
    "prev_class_mask_pred_flat     = tf.reshape(prev_class_mask_pred, shape=(-1, class_num))\n",
    "combined_class_mask_pred_flat = tf.concat((class_mask_pred_flat, prev_class_mask_pred_flat), axis=0)\n",
    "\n",
    "# get number of pixels and clusters (without background)\n",
    "num_cluster = tf.reduce_max(combined_identity_mask_flat)\n",
    "num_cluster = tf.cast(num_cluster, tf.int32)\n",
    "\n",
    "# cast masks into tf.int32 for one-hot encoding\n",
    "combined_identity_mask_flat = tf.cast(combined_identity_mask_flat, tf.int32)\n",
    "combined_class_mask_gt_flat = tf.cast(combined_class_mask_gt_flat, tf.int32)\n",
    "\n",
    "# one-hot encoding\n",
    "combined_identity_mask_flat -= 1\n",
    "combined_identity_mask_flat_one_hot = tf.one_hot(combined_identity_mask_flat, num_cluster)\n",
    "conbined_class_mask_gt_flat_one_hot = tf.one_hot(combined_class_mask_gt_flat, class_num)\n",
    "\n",
    "# ignore background pixels\n",
    "non_background_idx                  = tf.greater(combined_identity_mask_flat, -1)\n",
    "combined_instance_emb_flat          = tf.boolean_mask(combined_instance_emb_flat, non_background_idx)\n",
    "combined_identity_mask_flat         = tf.boolean_mask(combined_identity_mask_flat, non_background_idx)\n",
    "combined_identity_mask_flat_one_hot = tf.boolean_mask(combined_identity_mask_flat_one_hot, non_background_idx)\n",
    "combined_class_mask_gt_flat         = tf.boolean_mask(combined_class_mask_gt_flat, non_background_idx)\n",
    "\n",
    "# center count\n",
    "combined_identity_mask_flat_one_hot = tf.cast(combined_identity_mask_flat_one_hot, tf.float32)\n",
    "center_count = tf.reduce_sum(combined_identity_mask_flat_one_hot, axis=0)\n",
    "# add a small number to avoid division by zero\n",
    "\n",
    "# variance term\n",
    "embedding_sum_by_instance = tf.matmul(\n",
    "    tf.transpose(combined_instance_emb_flat), combined_identity_mask_flat_one_hot)\n",
    "centers = tf.math.divide_no_nan(embedding_sum_by_instance, center_count)\n",
    "gathered_center = tf.gather(centers, combined_identity_mask_flat, axis=1)\n",
    "gathered_center_count = tf.gather(center_count, combined_identity_mask_flat)\n",
    "combined_emb_t = tf.transpose(combined_instance_emb_flat)\n",
    "var_dist = tf.norm(combined_emb_t - gathered_center, ord=1, axis=0) - delta_var\n",
    "# changed from soft hinge loss to hard cutoff\n",
    "var_dist_pos = tf.square(tf.maximum(var_dist, 0))\n",
    "var_dist_by_instance = tf.math.divide_no_nan(var_dist_pos, gathered_center_count)\n",
    "num_cluster = tf.cast(num_cluster, tf.float32)\n",
    "variance_term = tf.math.divide_no_nan(\n",
    "    tf.reduce_sum(var_dist_by_instance),\n",
    "    tf.cast(num_cluster, tf.float32))\n",
    "\n",
    "# get instance to class mapping\n",
    "class_mask_gt = tf.expand_dims(class_mask_gt, axis=-1)\n",
    "# multiply classification with one hot flat identity mask\n",
    "combined_class_mask_gt_flat = tf.cast(combined_class_mask_gt_flat, tf.float32)\n",
    "combined_class_mask_gt_flat = tf.expand_dims(combined_class_mask_gt_flat, 1)\n",
    "filtered_class = tf.multiply(combined_identity_mask_flat_one_hot, combined_class_mask_gt_flat)\n",
    "# shrink to a 1 by num_of_cluster vector to map instance to class;\n",
    "# by reduce_max, any class other than 0 (background) stands out\n",
    "instance_to_class = tf.reduce_max(filtered_class, axis = [0])\n",
    "\n",
    "def distance_true_fn(num_cluster_by_class, centers_by_class):\n",
    "    centers_row_buffer = tf.ones((embedding_dim, num_cluster_by_class, num_cluster_by_class))\n",
    "    centers_by_class = tf.expand_dims(centers_by_class, axis=2)\n",
    "    centers_row = tf.multiply(centers_row_buffer, centers_by_class)\n",
    "    centers_col = tf.transpose(centers_row, perm=[0, 2, 1])\n",
    "    dist_matrix = centers_row - centers_col\n",
    "    idx2 = tf.ones((num_cluster_by_class, num_cluster_by_class))\n",
    "    diag = tf.ones((1, num_cluster_by_class))\n",
    "    diag = tf.reshape(diag, [-1])\n",
    "    idx2 = idx2 - tf.diag(diag)\n",
    "    idx2 = tf.cast(idx2, tf.bool)\n",
    "    idx2 = K.flatten(idx2)\n",
    "    dist_matrix = tf.reshape(dist_matrix, [embedding_dim, -1])\n",
    "    dist_matrix = tf.transpose(dist_matrix)\n",
    "    sampled_dist = tf.boolean_mask(dist_matrix, idx2)\n",
    "    distance_term = tf.square(tf.maximum(\n",
    "        2 * delta_d - tf.norm(sampled_dist, ord=1, axis=1), 0))\n",
    "    total_cluster_pair = num_cluster_by_class * (num_cluster_by_class - 1) + 1\n",
    "    total_cluster_pair = tf.cast(total_cluster_pair, tf.float32)\n",
    "    distance_term = tf.math.divide_no_nan(tf.reduce_sum(distance_term), total_cluster_pair)\n",
    "    return distance_term\n",
    "\n",
    "\n",
    "def distance_false_fn():\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "distance_term_total = 0.0\n",
    "# center distance term\n",
    "for i in range(class_num-1):\n",
    "    class_idx = tf.equal(instance_to_class, i+1)\n",
    "    centers_transpose = tf.transpose(centers)\n",
    "    centers_by_class_transpose = tf.boolean_mask(centers_transpose, class_idx)\n",
    "    centers_by_class = tf.transpose(centers_by_class_transpose)\n",
    "    num_cluster_by_class = tf.reduce_sum(tf.cast(class_idx, tf.float32))\n",
    "    num_cluster_by_class = tf.cast(num_cluster_by_class, tf.int32)\n",
    "    distance_term_subtotal = tf.cond(num_cluster_by_class > 0, \n",
    "                                    lambda: distance_true_fn(num_cluster_by_class, centers_by_class), \n",
    "                                    lambda: distance_false_fn())\n",
    "    distance_term_total += distance_term_subtotal\n",
    "\n",
    "# regularization term\n",
    "regularization_term = tf.reduce_mean(tf.norm(tf.squeeze(centers), ord=1, axis=0))\n",
    "\n",
    "# sum up terms\n",
    "instance_emb_sequence_loss = variance_term + distance_term_total + 0.01 * regularization_term\n",
    "semseg_loss = K.mean(K.categorical_crossentropy(\n",
    "    tf.cast(conbined_class_mask_gt_flat_one_hot, tf.float32), \n",
    "    tf.cast(combined_class_mask_pred_flat, tf.float32)))\n",
    "# masked mse for optical loss\n",
    "flow_mask = tf.greater(prev_class_mask_gt, 0)\n",
    "flow_mask = tf.cast(flow_mask, tf.float32)\n",
    "flow_mask = tf.expand_dims(flow_mask, axis = -1)\n",
    "masked_optical_flow_pred = tf.math.multiply(optical_flow_pred, flow_mask)\n",
    "optical_flow_loss = tf.reduce_mean(tf.square(masked_optical_flow_pred - optical_flow_gt))\n",
    "# loss = instance_emb_sequence_loss + semseg_loss + optical_flow_loss\n",
    "loss = optical_flow_loss\n",
    "loss = tf.reshape(loss, [-1])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    [masked_optical_flow_pred_, optical_flow_gt_] = sess.run(\n",
    "        [masked_optical_flow_pred, optical_flow_gt], \n",
    "        feed_dict = {'Placeholder:0': y, 'Placeholder_1:0': outputs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(flow_to_rgb(np.squeeze(optical_flow_gt_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(flow_to_rgb(np.squeeze(masked_optical_flow_pred_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class value:\n",
    "    def __init__(self, x):\n",
    "        self.val = x\n",
    "    \n",
    "    def increment(self):\n",
    "        self.val += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class temp:\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "        print(id(x))\n",
    "        print(id(self.x))\n",
    "        x.increment()\n",
    "        print(id(x))\n",
    "        print(id(self.x))\n",
    "        print(x.val)\n",
    "        print(self.x.val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = value(1)\n",
    "b = temp(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
