{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from datagen import SequenceDataGenerator\n",
    "from embedding_model import SequenceEmbeddingModel, sequence_loss_with_params\n",
    "from params import Params\n",
    "from IPython.display import clear_output\n",
    "from utils import *\n",
    "from evaluate import eval_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params()\n",
    "\n",
    "params.EMBEDDING_DIM            = 12\n",
    "params.BATCH_SIZE               = 1\n",
    "params.NUM_SHAPE                = 3\n",
    "params.NUM_CLASSES              = params.NUM_SHAPE + 1\n",
    "params.NUM_FILTER               = [256, 256, 128]\n",
    "params.ETH_MEAN_SHIFT_THRESHOLD = 1.5\n",
    "params.DELTA_VAR                = 0.5\n",
    "params.DELTA_D                  = 1.5\n",
    "params.IMG_SIZE                 = 256\n",
    "params.OUTPUT_SIZE              = 64\n",
    "params.SEQUENCE_LEN             = 20\n",
    "params.BACKBONE                 = 'xception'\n",
    "params.TASK                     = 'sequence'\n",
    "params.COLORS                   = np.random.random((params.NUM_SHAPE+1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yliu60\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yliu60\\Documents\\GitHub\\embedding_tracking\\deeplabv3\\model.py:87: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yliu60\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\yliu60\\Documents\\GitHub\\embedding_tracking\\embedding_model.py:110: The name tf.diag is deprecated. Please use tf.linalg.tensor_diag instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "model = SequenceEmbeddingModel(params)\n",
    "optim = Adam(lr = LEARNING_RATE)\n",
    "loss_function = sequence_loss_with_params(params)\n",
    "model.compile(optim, loss = loss_function)\n",
    "# clear_output()\n",
    "dg = SequenceDataGenerator(\n",
    "    num_shape    = params.NUM_SHAPE, \n",
    "    image_size   = params.IMG_SIZE,\n",
    "    sequence_len = params.SEQUENCE_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = SequenceDataGenerator(\n",
    "    num_shape    = params.NUM_SHAPE, \n",
    "    image_size   = params.IMG_SIZE,\n",
    "    sequence_len = params.SEQUENCE_LEN)\n",
    "sequence = dg.get_sequence()\n",
    "image_info = sequence[0]\n",
    "prev_image_info = sequence[1]\n",
    "x, y = prep_double_frame(image_info, prev_image_info, params)\n",
    "outputs = np.random.rand(1, 64, 64, 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "y_true = tf.placeholder(dtype = tf.float32, shape = (1, 64, 64, 6))\n",
    "y_pred = tf.placeholder(dtype = tf.float32, shape = (1, 64, 64, 34))\n",
    "\n",
    "# hyperparameters\n",
    "delta_var     = params.DELTA_VAR\n",
    "delta_d       = params.DELTA_D\n",
    "class_num     = params.NUM_CLASSES\n",
    "embedding_dim = params.EMBEDDING_DIM\n",
    "\n",
    "# unpack ground truth contents\n",
    "class_mask_gt      = y_true[:, :, :, 0]\n",
    "prev_class_mask_gt = y_true[:, :, :, 1]\n",
    "identity_mask      = y_true[:, :, :, 2]\n",
    "prev_identity_mask = y_true[:, :, :, 3]\n",
    "optical_flow_gt    = y_true[:, :, :, 4:5]\n",
    "\n",
    "# y_pred\n",
    "class_mask_pred      = y_pred[:, :, :, :class_num]\n",
    "prev_class_mask_pred = y_pred[:, :, :, class_num:(class_num * 2)]\n",
    "instance_emb         = y_pred[:, :, :, (class_num * 2):(class_num * 2 + embedding_dim)]\n",
    "prev_instance_emb    = y_pred[:, :, :, (class_num * 2 + embedding_dim):(class_num * 2 + embedding_dim * 2)]\n",
    "optical_flow_pred    = y_pred[:, :, :, (class_num * 2 + embedding_dim * 2):]\n",
    "\n",
    "# flatten and combine\n",
    "# --identity mask gt\n",
    "identity_mask_flat            = K.flatten(identity_mask)\n",
    "prev_identity_mask_flat       = K.flatten(prev_identity_mask)\n",
    "combined_identity_mask_flat   = tf.concat((identity_mask_flat, prev_identity_mask_flat), axis=0)\n",
    "# --instance embedding pred\n",
    "instance_emb_flat             = tf.reshape(instance_emb, shape=(-1, embedding_dim))\n",
    "prev_instance_emb_flat        = tf.reshape(prev_instance_emb, shape=(-1, embedding_dim))\n",
    "combined_instance_emb_flat     = tf.concat((instance_emb_flat, prev_instance_emb_flat), axis=0)\n",
    "# --class mask gt\n",
    "class_mask_gt_flat            = K.flatten(class_mask_gt)\n",
    "prev_class_mask_gt_flat       = K.flatten(prev_class_mask_gt)\n",
    "combined_class_mask_gt_flat   = tf.concat((class_mask_gt_flat, prev_class_mask_gt_flat), axis=0)\n",
    "# --class mask pred\n",
    "class_mask_pred_flat          = tf.reshape(class_mask_pred, shape=(-1, class_num))\n",
    "prev_class_mask_pred_flat     = tf.reshape(prev_class_mask_pred, shape=(-1, class_num))\n",
    "combined_class_mask_pred_flat = tf.concat((class_mask_pred_flat, prev_class_mask_pred_flat), axis=0)\n",
    "\n",
    "# get number of pixels and clusters (without background)\n",
    "num_cluster = tf.reduce_max(combined_identity_mask_flat)\n",
    "num_cluster = tf.cast(num_cluster, tf.int32)\n",
    "\n",
    "# cast masks into tf.int32 for one-hot encoding\n",
    "combined_identity_mask_flat = tf.cast(combined_identity_mask_flat, tf.int32)\n",
    "combined_class_mask_gt_flat = tf.cast(combined_class_mask_gt_flat, tf.int32)\n",
    "\n",
    "# one-hot encoding\n",
    "combined_identity_mask_flat -= 1\n",
    "combined_identity_mask_flat_one_hot = tf.one_hot(combined_identity_mask_flat, num_cluster)\n",
    "conbined_class_mask_gt_flat_one_hot = tf.one_hot(combined_class_mask_gt_flat, class_num)\n",
    "\n",
    "# ignore background pixels\n",
    "non_background_idx                  = tf.greater(combined_identity_mask_flat, -1)\n",
    "combined_instance_emb_flat          = tf.boolean_mask(combined_instance_emb_flat, non_background_idx)\n",
    "combined_identity_mask_flat         = tf.boolean_mask(combined_identity_mask_flat, non_background_idx)\n",
    "combined_identity_mask_flat_one_hot = tf.boolean_mask(combined_identity_mask_flat_one_hot, non_background_idx)\n",
    "combined_class_mask_gt_flat         = tf.boolean_mask(combined_class_mask_gt_flat, non_background_idx)\n",
    "\n",
    "# center count\n",
    "center_count = tf.reduce_sum(tf.cast(combined_identity_mask_flat_one_hot, dtype=tf.float32), axis=0)\n",
    "\n",
    "# variance term\n",
    "embedding_sum_by_instance = tf.matmul(\n",
    "    tf.transpose(combined_instance_emb_flat), tf.cast(combined_identity_mask_flat_one_hot, dtype=tf.float32))\n",
    "centers = tf.divide(embedding_sum_by_instance, center_count)\n",
    "gathered_center = tf.gather(centers, combined_identity_mask_flat, axis=1)\n",
    "gathered_center_count = tf.gather(center_count, combined_identity_mask_flat)\n",
    "combined_emb_t = tf.transpose(combined_instance_emb_flat)\n",
    "var_dist = tf.norm(combined_emb_t - gathered_center, ord=1, axis=0) - delta_var\n",
    "# changed from soft hinge loss to hard cutoff\n",
    "var_dist_pos = tf.square(tf.maximum(var_dist, 0))\n",
    "var_dist_by_instance = tf.divide(var_dist_pos, gathered_center_count)\n",
    "num_cluster = tf.cast(num_cluster, tf.float32)\n",
    "variance_term = tf.reduce_sum(var_dist_by_instance) / num_cluster\n",
    "\n",
    "# get instance to class mapping\n",
    "class_mask_gt = tf.expand_dims(class_mask_gt, axis=-1)\n",
    "# multiply classification with one hot flat identity mask\n",
    "combined_identity_mask_flat_one_hot = tf.cast(combined_identity_mask_flat_one_hot, tf.float32)\n",
    "combined_class_mask_gt_flat = tf.cast(combined_class_mask_gt_flat, tf.float32)\n",
    "combined_class_mask_gt_flat = tf.expand_dims(combined_class_mask_gt_flat, 1)\n",
    "filtered_class = tf.multiply(combined_identity_mask_flat_one_hot, combined_class_mask_gt_flat)\n",
    "# shrink to a 1 by num_of_cluster vector to map instance to class;\n",
    "# by reduce_max, any class other than 0 (background) stands out\n",
    "instance_to_class = tf.reduce_max(filtered_class, axis = [0])\n",
    "\n",
    "def distance_true_fn(num_cluster_by_class, centers_by_class):\n",
    "    centers_row_buffer = tf.ones((embedding_dim, num_cluster_by_class, num_cluster_by_class))\n",
    "    centers_by_class = tf.expand_dims(centers_by_class, axis=2)\n",
    "    centers_row = tf.multiply(centers_row_buffer, centers_by_class)\n",
    "    centers_col = tf.transpose(centers_row, perm=[0, 2, 1])\n",
    "    dist_matrix = centers_row - centers_col\n",
    "    idx2 = tf.ones((num_cluster_by_class, num_cluster_by_class))\n",
    "    diag = tf.ones((1, num_cluster_by_class))\n",
    "    diag = tf.reshape(diag, [-1])\n",
    "    idx2 = idx2 - tf.diag(diag)\n",
    "    idx2 = tf.cast(idx2, tf.bool)\n",
    "    idx2 = K.flatten(idx2)\n",
    "    dist_matrix = tf.reshape(dist_matrix, [embedding_dim, -1])\n",
    "    dist_matrix = tf.transpose(dist_matrix)\n",
    "    sampled_dist = tf.boolean_mask(dist_matrix, idx2)\n",
    "    distance_term = tf.square(tf.maximum(\n",
    "        2 * delta_d - tf.norm(sampled_dist, ord=1, axis=1), 0))\n",
    "    distance_term = tf.reduce_sum(\n",
    "        distance_term) / tf.cast(num_cluster_by_class * (num_cluster_by_class - 1) + 1, tf.float32)\n",
    "    return distance_term\n",
    "\n",
    "\n",
    "def distance_false_fn():\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "distance_term_total = 0.0\n",
    "# center distance term\n",
    "for i in range(class_num-1):\n",
    "    class_idx = tf.equal(instance_to_class, i+1)\n",
    "    centers_transpose = tf.transpose(centers)\n",
    "    centers_by_class_transpose = tf.boolean_mask(centers_transpose, class_idx)\n",
    "    centers_by_class = tf.transpose(centers_by_class_transpose)\n",
    "    num_cluster_by_class = tf.reduce_sum(tf.cast(class_idx, tf.float32))\n",
    "    num_cluster_by_class = tf.cast(num_cluster_by_class, tf.int32)\n",
    "    distance_term_subtotal = tf.cond(num_cluster_by_class > 0, \n",
    "                                    lambda: distance_true_fn(num_cluster_by_class, centers_by_class), \n",
    "                                    lambda: distance_false_fn())\n",
    "    distance_term_total += distance_term_subtotal\n",
    "\n",
    "# regularization term\n",
    "regularization_term = tf.reduce_mean(tf.norm(tf.squeeze(centers), ord=1, axis=0))\n",
    "\n",
    "# sum up terms\n",
    "instance_emb_sequence_loss = variance_term + distance_term_total + 0.01 * regularization_term\n",
    "semseg_loss = K.mean(K.categorical_crossentropy(\n",
    "    tf.cast(conbined_class_mask_gt_flat_one_hot, tf.float32), \n",
    "    tf.cast(combined_class_mask_pred_flat, tf.float32)))\n",
    "optical_flow_loss = tf.reduce_mean(tf.square(optical_flow_pred - optical_flow_gt))\n",
    "loss = instance_emb_sequence_loss + semseg_loss + optical_flow_loss\n",
    "loss = tf.reshape(loss, [-1])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    [loss_] = sess.run(\n",
    "        [loss], \n",
    "        feed_dict = {'Placeholder:0': y, 'Placeholder_1:0': outputs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "nan = float('nan')\n",
    "step = 0\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for _ in range(100):\n",
    "        sequence = dg.get_sequence()\n",
    "        for i in range(params.SEQUENCE_LEN - 1):\n",
    "            step += 1\n",
    "            image_info = sequence[i]\n",
    "            prev_image_info = sequence[i+1]\n",
    "            x, y = prep_double_frame(image_info, prev_image_info, params)\n",
    "            history = model.fit(x, y, batch_size = 1, verbose = False)\n",
    "            loss_history.append(history.history['loss'][-1])\n",
    "            if step % 20 == 19:\n",
    "                clear_output()\n",
    "                visualize_history(loss_history, f'loss, total step: {step}')\n",
    "                sequence = dg.get_sequence()\n",
    "                pair = sequence[0:2]\n",
    "                eval_pair(model, pair, params)\n",
    "    model.save('sequence.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
